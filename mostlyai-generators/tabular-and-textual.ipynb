{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mostlyai.sdk import MostlyAI\n",
    "\n",
    "# load original data with news headlines\n",
    "repo_url = 'https://github.com/mostly-ai/public-demo-data'\n",
    "trn_df = pd.read_parquet(f'{repo_url}/raw/refs/heads/dev/headlines/headlines.parquet')\n",
    "\n",
    "# instantiate SDK\n",
    "mostly = MostlyAI()\n",
    "\n",
    "# print out available LANGUAGE models\n",
    "print(mostly.models()[\"LANGUAGE\"])\n",
    "\n",
    "# train a generator; increase max_training_time to improve quality\n",
    "g = mostly.train(config={\n",
    "    'name': 'Headlines',                   # name of the generator\n",
    "    'tables': [{                           # provide list of table(s)\n",
    "        'name': 'headlines',               # name of the table\n",
    "        'data': trn_df,                    # the original data as pd.DataFrame\n",
    "        'columns': [                       # configure TABULAR + LANGUAGE cols\n",
    "            {'name': 'category', 'model_encoding_type': 'TABULAR_CATEGORICAL'},\n",
    "            {'name': 'date', 'model_encoding_type': 'TABULAR_DATETIME'},\n",
    "            {'name': 'headline', 'model_encoding_type': 'LANGUAGE_TEXT'},\n",
    "        ],\n",
    "        'tabular_model_configuration': {             # tabular model configuration (optional)\n",
    "            'max_training_time': 5,                  # cap runtime for demo; set None for max accuracy\n",
    "        },\n",
    "        'language_model_configuration': {             # language model configuration (optional)\n",
    "            'max_training_time': 5,                   # cap runtime for demo; set None for max accuracy\n",
    "            'model': 'MOSTLY_AI/LSTMFromScratch-3m',  # use a light-weight LSTM model, trained from scratch (GPU recommended)\n",
    "            #'model': 'microsoft/phi-1.5',            # alternatively use a pre-trained HF-hosted LLM model (GPU required)\n",
    "        }\n",
    "    }],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seed = pd.DataFrame({'category': ['WELLNESS'] * 100})\n",
    "sd = mostly.generate(g, seed=df_seed)\n",
    "df_synthetic = sd.data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mostly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
